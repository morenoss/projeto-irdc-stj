/******************************************************************************
PREPARA√á√ÉO - MACROS-CAMINHOS E IN√çCIO DO LOG DE GRAVA√á√ÉO DOS RESULTADOS
*******************************************************************************/
* Definindo os diret√≥rios de trabalho
local basedados     "C:\Users\...INFORME AQUI O DIRET√ìRIO ONDE O SCRIPT EST√Å SALVO"
local resultados    "`basedados'/Resultados"
local pacotes       "`basedados'/Pacotes" 

*Instala e ativa pacotes locais para heatmap
adopath + "`pacotes'"

* Fechar qualquer log aberto
capture log close

* Limpa o Stata e o Python
clear
clear python
set more off

* Fecha o log se j√° estiver aberto
capture log close IRDC_Resultados

* Salvar log das estat√≠sticas descritivas e do codebook
log using "`resultados'\IRDC_RAC.log", replace text name ("IRDC_Resultados")

/*******************************************************************************
Projeto:            √çndice de Risco de Descumprimento Contratual (IRDC)
Autor:              Moreno Souto Santiago
Fonte dos Dados:    Painel de Informa√ß√µes Cont√°beis dos Fornecedores do STJ
Ferramentas:        Stata 18 + Python (SMOTENC)
Descri√ß√£o:          
Este script executa a an√°lise preditiva do IRDC com base em dados cont√°beis e cadastrais
dos fornecedores do STJ. As etapas incluem:

1. **Importa√ß√£o e transforma√ß√£o dos dados**: consolida√ß√£o dos indicadores cont√°beis,
   an√°lise descritiva inicial e prepara√ß√£o da base para modelagem.

2. **Matriz de correla√ß√£o inicial das vari√°veis cont√≠nuas**: c√°lculo da matriz de
   correla√ß√£o antes da imputa√ß√£o e cria√ß√£o dos √≠ndices sint√©ticos, permitindo acompanhar
   a evolu√ß√£o das rela√ß√µes entre vari√°veis conforme os dados s√£o atualizados ou transformados.

3. **Winsoriza√ß√£o das vari√°veis cont√≠nuas**: aplica√ß√£o do corte nos percentis 1% e 99%
   para reduzir o impacto de outliers extremos, preservando a variabilidade e robustez
   das an√°lises subsequentes.

4. **Estat√≠sticas descritivas por grupo**: gera√ß√£o de tabelas de estat√≠sticas descritivas
   (m√©dia, desvio padr√£o, m√≠nimo, m√°ximo) para empresas penalizadas e n√£o penalizadas,
   antes e ap√≥s a winsoriza√ß√£o, facilitando an√°lise comparativa de perfil e identifica√ß√£o de padr√µes.

5. **Imputa√ß√£o de valores faltantes**: preenchimento de dados ausentes por m√©dia ou mediana,
   conforme o coeficiente de varia√ß√£o, para garantir integridade e qualidade da base.

6. **Padroniza√ß√£o z-score de todas as vari√°veis cont√≠nuas**: todas as vari√°veis cont√≠nuas e indicadores
   foram transformados para escala padr√£o (m√©dia 0, desvio-padr√£o 1), conferindo maior robustez,
   comparabilidade e estabilidade aos modelos preditivos subsequentes.

7. **Cria√ß√£o dos √≠ndices sint√©ticos**: combina√ß√£o de vari√°veis colineares j√° padronizadas
   em √≠ndices sint√©ticos para reduzir dimensionalidade e multicolinearidade, facilitando a modelagem.

8. **Matriz de correla√ß√£o final dos √≠ndices sint√©ticos e vari√°veis cont√≠nuas**:
   c√°lculo da matriz ap√≥s a imputa√ß√£o, padroniza√ß√£o e cria√ß√£o dos √≠ndices para validar a estrutura dos dados.

9. **Separa√ß√£o das amostras em treinamento (80%) e teste (20%)**: a separa√ß√£o das
   amostras √© realizada obedecendo a propor√ß√£o exata de empresas penalizadas e n√£o penalizadas.

10. **Balanceamento da amostra de treinamento**: aplica√ß√£o da t√©cnica SMOTENC em Python para lidar com
    desbalanceamento da vari√°vel dependente (penaliza√ß√£o pelo STJ), com codifica√ß√£o de
    vari√°veis categ√≥ricas e posterior reintegra√ß√£o ao Stata.

11. **Agrupamento de CNAEs raros**: defini√ß√£o do m√≠nimo de ocorr√™ncias para manter CNAE
    como categoria isolada (local freq_minima = 10). As categorias com menor frequ√™ncia
    foram agrupadas sob o c√≥digo -1 para reduzir a sparsidade da matriz de vari√°veis dummies
    e aumentar a estabilidade dos coeficientes.

12. **Convers√£o e cria√ß√£o de vari√°veis dummies para vari√°veis categ√≥ricas**:
    transforma√ß√£o de vari√°veis categ√≥ricas em vari√°veis dummy ap√≥s o balanceamento.

13. **Modelagem e avalia√ß√£o preditiva**:
    - Modelo logit completo (com todas as vari√°veis)
    - Modelos logit com sele√ß√£o stepwise
    - Modelo com penaliza√ß√£o LASSO
    Todos os modelos s√£o avaliados com m√©tricas como acur√°cia, Kappa, NIR, teste de McNemar,
    curvas ROC e defini√ß√£o do ponto de corte ideal baseado na equival√™ncia entre
    sensibilidade e especificidade. As m√©tricas s√£o aplicadas nos conjuntos de treinamento e teste.

Objetivo:
Identificar o melhor modelo para predi√ß√£o da vari√°vel bin√°ria `FoiPenalizadoSTJ`,
avaliando o poder explicativo de indicadores cont√°beis, porte, natureza jur√≠dica, CNAE,
e vari√°veis de hist√≥rico contratual da empresa.

√öltima atualiza√ß√£o: 31/07/2025
*******************************************************************************/


   

/*******************************************************************************
ETAPA 1 - IMPORTA√á√ÉO, AN√ÅLISE DESCRITIVA DAS VARI√ÅVEIS E TRANSFORMA√á√ÉO 
*******************************************************************************/
* Definindo o diret√≥rio de trabalho e importando os dados do Excel
cd "`basedados'"
import excel "Dados_novo", sheet("Tabela 4") firstrow clear

/*******************************************************************************
1.1 - Executar estat√≠sticas descritivas para todas as vari√°veis
*******************************************************************************/
summarize LiqCorrente LiqGeral LiqCorAjust SolvGeral EndGeral CompEndivid IndepFin ImobilPL ImobRecNC PtpCapTerce GiroAtivo MargOp MargLiq ROI ROE vlrcontrato QtdeCNAEsSecundarios IdadedeAnos QtePenalOutrosOrgaos

* Estat√≠sticas descritivas separadas por penaliza√ß√£o
by FoiPenalizadoSTJ, sort: summarize LiqCorrente LiqGeral LiqCorAjust SolvGeral EndGeral CompEndivid IndepFin ImobilPL ImobRecNC PtpCapTerce GiroAtivo MargOp MargLiq ROI ROE vlrcontrato QtdeCNAEsSecundarios IdadedeAnos QtePenalOutrosOrgaos

* Bloco para salvar as estat√≠sticas descritivas originais por grupo
tabstat LiqCorrente LiqGeral LiqCorAjust SolvGeral EndGeral CompEndivid IndepFin ImobilPL ImobRecNC PtpCapTerce GiroAtivo MargOp MargLiq ROI ROE vlrcontrato QtdeCNAEsSecundarios IdadedeAnos QtePenalOutrosOrgaos, ///
    statistics(mean sd min max n) by(FoiPenalizadoSTJ)
	
*Bloco de estat√≠ticas das vari√°veis qualitativas

tabulate Porte
tabulate NaturezaJuridica
tabulate CNAE

quietly egen cnpjs = tag(CNPJ)
tabulate FoiPenalizadoSTJ if cnpjs == 1, missing


// Frequ√™ncia com percentual
tabulate Porte, missing
tabulate NaturezaJuridica, missing
tabulate CNAE, missing


tabulate Porte FoiPenalizadoSTJ, column
tabulate NaturezaJuridica FoiPenalizadoSTJ, row
tabulate CNAE FoiPenalizadoSTJ, cell

/*******************************************************************************
1.1.2 Matriz de Correla√ß√£o das Vari√°veis Cont√≠nuas (STATA + Heatmap)
*******************************************************************************/

* 1. Defina as vari√°veis cont√≠nuas 
local var_continuas LiqCorrente LiqGeral LiqCorAjust SolvGeral EndGeral CompEndivid IndepFin ImobilPL ImobRecNC PtpCapTerce GiroAtivo MargOp MargLiq ROI ROE vlrcontrato QtdeCNAEsSecundarios IdadedeAnos QtePenalOutrosOrgaos

* 2. Calcule a matriz de correla√ß√£o em Stata
correlate `var_continuas', means
matrix C = r(C)

* 3. Gere o heatmap com o pacote heatplot

heatplot C, ///
    color(RdBu) ///
    legend(on) aspectratio(1) ///
    xlabel(, labsize(vsmall) angle(45)) ///
    ylabel(, labsize(vsmall)) ///
    title("Matriz de Correla√ß√£o das Vari√°veis Cont√≠nuas")

* 4. Salve o gr√°fico
graph export "heatmap_correlacao.png", replace width(2400)


*/*******************************************************************************
1.2 ‚Äì Winsoriza√ß√£o das vari√°veis cont√≠nuas (antes da imputa√ß√£o)
*******************************************************************************/

* Substituir todos os valores missing (.) de vlrcontrato por 0
replace vlrcontrato = 0 if missing(vlrcontrato)

ssc install winsor2, replace
local winsor_vars LiqCorrente LiqGeral LiqCorAjust SolvGeral EndGeral CompEndivid IndepFin ImobilPL ImobRecNC PtpCapTerce GiroAtivo MargOp MargLiq ROI ROE vlrcontrato

foreach var of local winsor_vars {
    winsor2 `var', cuts(1 99) replace
}

/*******************************************************************************
1.3 - Executar estat√≠sticas descritivas para todas as vari√°veis ap√≥s wisoriza√ß√£o
*******************************************************************************/
summarize LiqCorrente LiqGeral LiqCorAjust SolvGeral EndGeral CompEndivid IndepFin ImobilPL ImobRecNC PtpCapTerce GiroAtivo MargOp MargLiq ROI ROE vlrcontrato QtdeCNAEsSecundarios IdadedeAnos QtePenalOutrosOrgaos

* Estat√≠sticas descritivas separadas por penaliza√ß√£o
by FoiPenalizadoSTJ, sort: summarize LiqCorrente LiqGeral LiqCorAjust SolvGeral EndGeral CompEndivid IndepFin ImobilPL ImobRecNC PtpCapTerce GiroAtivo MargOp MargLiq ROI ROE vlrcontrato QtdeCNAEsSecundarios IdadedeAnos QtePenalOutrosOrgaos

* Bloco para salvar as estat√≠sticas descritivas ap√≥s a winsoriza√ß√£o por grupo
tabstat LiqCorrente LiqGeral LiqCorAjust SolvGeral EndGeral CompEndivid IndepFin ImobilPL ImobRecNC PtpCapTerce GiroAtivo MargOp MargLiq ROI ROE vlrcontrato QtdeCNAEsSecundarios IdadedeAnos QtePenalOutrosOrgaos, ///
    statistics(mean sd min max n) by(FoiPenalizadoSTJ)

/*******************************************************************************
ETAPA 2 - TRANSFORMA√á√ÉO DE VARI√ÅVEIS 
*******************************************************************************/

* Dropar CNPJ antes de exportar
drop CNPJ


/*******************************************************************************
2.1 - Imputa√ß√£o dos valores faltantes (missing) com a m√©dia ou mediana 
*******************************************************************************/

* Lista de vari√°veis com dados faltantes para imputa√ß√£o
local imput_vars GiroAtivo MargOp MargLiq ROI ROE RecBruta LucroBruto LucroLiquido

* Inicializar contadores
local conta_media = 0
local conta_mediana = 0

* Imputa√ß√£o adaptativa: m√©dia se CV <= 0.3, mediana se CV > 0.3
foreach var of local imput_vars {
    
    quietly summarize `var' if `var' > 0, detail
    local media = r(mean)
    local desvio = r(sd)
    local mediana = r(p50)

    * Calcular o Coeficiente de Varia√ß√£o (CV)
    local cv = `desvio' / `media'

    * Escolher m√©todo conforme o CV
    if `cv' <= 0.3 {
        replace `var' = `media' if missing(`var') | `var' == 0
        local conta_media = `conta_media' + 1
        di as result "üîß `var': imputado com M√âDIA (CV = " %4.3f `cv' ")"
    }
    else {
        replace `var' = `mediana' if missing(`var') | `var' == 0
        local conta_mediana = `conta_mediana' + 1
        di as result "üîß `var': imputado com MEDIANA (CV = " %4.3f `cv' ")"
    }
}

* Exibir tabela resumo
di as text "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê"
di as text " Resumo da Imputa√ß√£o de Vari√°veis (Crit√©rio: CV <= 0.3 ‚Üí M√âDIA)"
di as text "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ"
di " Vari√°veis imputadas com M√âDIA:   `conta_media'"
di " Vari√°veis imputadas com MEDIANA: `conta_mediana'"
di as text " Total de vari√°veis imputadas:    " `=`conta_media' + `conta_mediana''
di as text "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê"

/*******************************************************************************
2.2 - Cria√ß√£o dos √çndices Sint√©ticos (Z-SCORE)
*******************************************************************************/

/* (A) Liquidez_Media: combina LiqCorrente, LiqGeral, SolvGeral e IndepFin */
foreach var in LiqCorrente LiqGeral SolvGeral IndepFin {
    egen z_`var' = std(`var')
}
gen Liquidez_Media_Z = (z_LiqCorrente + z_LiqGeral + z_SolvGeral + z_IndepFin)/4

/* (B) Estrutura_Media: combina ImobilPL e PtpCapTerce  */
foreach var in ImobilPL PtpCapTerce {
    egen z_`var' = std(`var')
}
gen Estrutura_Media_Z = (z_ImobilPL + z_PtpCapTerce)/2

/* (C) Margem_Media: combina MargOp e MargLiq */
egen z_MargOp = std(MargOp)
egen z_MargLiq = std(MargLiq)
gen Margem_Media_Z = (z_MargOp + z_MargLiq)/2

/* Padronize as vari√°veis cont√≠nuas que ficar√£o SEPARADAS */
egen z_LiqCorAjust = std(LiqCorAjust)
egen z_EndGeral = std(EndGeral)
egen z_ImobRecNC   = std(ImobRecNC)
egen z_CompEndivid = std(CompEndivid)
egen z_GiroAtivo   = std(GiroAtivo)
egen z_ROI         = std(ROI)
egen z_ROE         = std(ROE)
egen z_vlrcontrato = std(vlrcontrato)
egen z_QtdeCNAEsSecundarios = std(QtdeCNAEsSecundarios)
egen z_QtePenalOutrosOrgaos = std(QtePenalOutrosOrgaos)
egen z_IdadedeAnos = std(IdadedeAnos)



/*******************************************************************************
2.2.2 - Matriz de correla√ß√£o dos √≠ndices sint√©ticos (e outras vari√°veis cont√≠nuas)
*******************************************************************************/

/* Defina as vari√°veis cont√≠nuas finais para correla√ß√£o */
local correl_final Liquidez_Media_Z Estrutura_Media_Z Margem_Media_Z ///
    z_LiqCorAjust z_EndGeral z_ImobRecNC z_CompEndivid z_GiroAtivo ///
    z_ROI z_ROE z_vlrcontrato z_QtdeCNAEsSecundarios z_QtePenalOutrosOrgaos z_IdadedeAnos

/* Calcule a matriz de correla√ß√£o */
correlate `correl_final', means
matrix C = r(C)

/* Gere o heatmap (se tiver heatplot instalado) */
heatplot C, ///
    color(RdBu) ///
    legend(on) aspectratio(1) ///
    xlabel(, labsize(vsmall) angle(45)) ///
    ylabel(, labsize(vsmall)) ///
    title("Matriz de Correla√ß√£o dos Indicadores Sint√©ticos e Cont√≠nuos")

graph export "heatmap_correlacao_indices.png", replace width(2400)


/*******************************************************************************
ETAPA 3 - SEPARA√á√ÉO DOS DADOS EM CONJUNTOS DE TREINAMENTO E TESTE COM PROPOR√á√ïES EXATAS
*******************************************************************************/
* Definir uma seed para reprodutibilidade
set seed 12345

* Gerar uma vari√°vel aleat√≥ria uniforme entre 0 e 1
generate u = runiform()

* Ordenar aleatoriamente dentro de cada classe
sort FoiPenalizadoSTJ u

* Gerar √≠ndices de observa√ß√£o dentro de cada classe
by FoiPenalizadoSTJ: gen obs_no = _n
by FoiPenalizadoSTJ: gen total_obs = _N

* Calcular o ponto de corte para 80% das observa√ß√µes
by FoiPenalizadoSTJ: gen cutoff = ceil(0.80 * total_obs)

* Criar o indicador de treinamento
gen train = 0
replace train = 1 if obs_no <= cutoff

* Verificar distribui√ß√£o antes do SMOTE
tabulate FoiPenalizadoSTJ train

/*******************************************************************************
ETAPA 3.1 - SALVAR OS LABELS PARA RESTAURAR DEPOIS DO SMOTE
*******************************************************************************/
* Criar um arquivo tempor√°rio para armazenar labels
tempfile labels_backup
label save using "`labels_backup'.do", replace

/*******************************************************************************
ETAPA 3.2 - EXPORTAR BASES PARA O PYTHON (TREINO PARA SMOTE, TESTE SEPARADO)
*******************************************************************************/
* Exportar conjunto de treino
preserve
keep if train == 1
export delimited using "train_data.csv", replace
restore

* Exportar conjunto de teste
preserve
keep if train == 0
export delimited using "test_data.csv", replace
restore

/*******************************************************************************
ETAPA 4 - APLICAR SMOTENC NO PYTHON
*******************************************************************************/
python:
import pandas as pd
import numpy as np
from imblearn.over_sampling import SMOTENC
import traceback  # Para melhor tratamento de erros

print("--- Iniciando Bloco Python ---")
try:
    # Carregar conjunto de treino do Stata
    print("Carregando train_data.csv...")
    df = pd.read_csv("train_data.csv")
    print(f"Dados carregados: {df.shape[0]} linhas, {df.shape[1]} colunas")
    print("Colunas originais:", df.columns.tolist())
    print("Contagem inicial de 'FoiPenalizadoSTJ':\n", df["FoiPenalizadoSTJ"].value_counts())

    # Separar vari√°vel-alvo e explicativas
    X = df.drop(columns=["FoiPenalizadoSTJ", "train"], errors="ignore")
    y = df["FoiPenalizadoSTJ"]

    # Definir vari√°veis categ√≥ricas PELOS NOMES (mais robusto)
    categorical_feature_names = ['Porte', 'CNAE', 'DivisaoCNAE', 'NaturezaJuridica']

    # Verificar se as colunas existem em X
    missing_cols = [col for col in categorical_feature_names if col not in X.columns]
    if missing_cols:
        raise ValueError(f"As seguintes colunas categ√≥ricas n√£o foram encontradas em X: {missing_cols}")

    # Obter os √≠ndices das colunas categ√≥ricas
    categorical_features_indices = [X.columns.get_loc(col) for col in categorical_feature_names]
    print(f"√çndices das features categ√≥ricas: {categorical_features_indices}")
    print("Tipos das features categ√≥ricas em X:\n", X[categorical_feature_names].dtypes)

    # Ajustar k_neighbors: deve ser menor que o n√∫mero de amostras da classe minorit√°ria
    min_class_count = y.value_counts().min()
    k_neighbors_val = min(5, min_class_count - 1)
    if k_neighbors_val < 1:
        print(f"AVISO: Classe minorit√°ria tem apenas {min_class_count} amostras. N√£o √© poss√≠vel aplicar SMOTENC com k_neighbors >= 1.")
        raise ValueError(f"N√£o √© poss√≠vel aplicar SMOTENC, k_neighbors ({k_neighbors_val}) seria menor que 1.")
    else:
        print(f"Aplicando SMOTENC com k_neighbors={k_neighbors_val}...")
        smote_nc = SMOTENC(categorical_features=categorical_features_indices,
                           random_state=42,
                           k_neighbors=k_neighbors_val)

        X_resampled, y_resampled = smote_nc.fit_resample(X, y)
        print("SMOTENC conclu√≠do.")
        print(f"Tamanho ap√≥s resample: {X_resampled.shape[0]} linhas")
        print("Contagem de 'FoiPenalizadoSTJ' ap√≥s resample:\n", pd.Series(y_resampled).value_counts())

        # Criar DataFrame balanceado a partir do resultado do SMOTENC
        df_resampled = pd.DataFrame(X_resampled, columns=X.columns)

        # Adicionar a vari√°vel alvo e a marca√ß√£o de treino
        df_resampled["FoiPenalizadoSTJ"] = y_resampled
        df_resampled["train"] = 1

        # Verificar se as colunas categ√≥ricas foram mantidas
        print("Colunas no df_resampled final:", df_resampled.columns.tolist())
        missing_cols_after = [col for col in categorical_feature_names if col not in df_resampled.columns]
        if missing_cols_after:
            print(f"AVISO: As colunas {missing_cols_after} N√ÉO est√£o presentes ap√≥s SMOTENC!")
        else:
            print("Colunas categ√≥ricas presentes ap√≥s SMOTENC.")
            print("Tipos das features categ√≥ricas ap√≥s SMOTENC:\n", df_resampled[categorical_feature_names].dtypes)
            print("Primeiras linhas do df_resampled:\n", df_resampled.head())

        # üîÅ Converter vari√°veis categ√≥ricas e salvar mapeamentos
        print("Convertendo vari√°veis categ√≥ricas do treino para c√≥digos num√©ricos e salvando mapeamentos...")

        categorical_mappings = {}

        for col in categorical_feature_names:
            df_resampled[col] = df_resampled[col].astype("category")

            # Salvar mapeamento antes de converter para c√≥digos
            mapping = dict(enumerate(df_resampled[col].cat.categories))
            categorical_mappings[col] = mapping

            # Substituir coluna por c√≥digos num√©ricos
            df_resampled[col] = df_resampled[col].cat.codes

            # Exportar mapeamento para CSV
            mapping_df = pd.DataFrame(mapping.items(), columns=[f"{col}_code", f"{col}_label"])
            mapping_df.to_csv(f"{col}_mapping.csv", index=False, encoding="utf-8")
            print(f"‚úÖ Mapeamento salvo: {col}_mapping.csv")

        print("Convers√£o no treino conclu√≠da.")

    # Salvar dataset balanceado em CSV (codificado em UTF-8)
    print("Salvando train_data_balanced.csv...")
    df_resampled.to_csv("train_data_balanced.csv", index=False, encoding='utf-8')
    print("Arquivo train_data_balanced.csv salvo com sucesso.")

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # ‚úÖ ETAPA EXTRA: Converter vari√°veis categ√≥ricas do conjunto de teste com os mesmos c√≥digos do treino
    print("Carregando test_data.csv para convers√£o das vari√°veis categ√≥ricas...")
    df_test = pd.read_csv("test_data.csv")
    print(f"Conjunto de teste carregado: {df_test.shape[0]} linhas")

    # Verificar se as colunas categ√≥ricas est√£o presentes
    missing_test_cols = [col for col in categorical_feature_names if col not in df_test.columns]
    if missing_test_cols:
        raise ValueError(f"‚ö†Ô∏è Colunas categ√≥ricas ausentes no teste: {missing_test_cols}")

    print("Aplicando os mesmos mapeamentos do treino ao conjunto de teste...")

    for col in categorical_feature_names:
        mapping_df = pd.read_csv(f"{col}_mapping.csv", encoding="utf-8")
        mapping_dict = dict(zip(mapping_df[f"{col}_label"], mapping_df[f"{col}_code"]))

        # Aplicar o mapeamento manualmente
        df_test[col] = df_test[col].map(mapping_dict)

        # Se houver valores n√£o encontrados no mapeamento, definir como -1
        df_test[col] = df_test[col].fillna(-1).astype(int)

        print(f"‚úÖ Coluna '{col}' convertida com mapeamento do treino.")

    # Salvar novamente o arquivo convertido
    df_test.to_csv("test_data.csv", index=False, encoding="utf-8")
    print("Arquivo test_data.csv salvo com sucesso ap√≥s convers√£o.")

except Exception as e:
    print("--- ERRO NO BLOCO PYTHON ---")
    print(traceback.format_exc())
    pd.DataFrame().to_csv("train_data_balanced.csv", index=False)
    print("Arquivo train_data_balanced.csv vazio criado devido a erro.")

print("--- Fim Bloco Python ---")
end


/*******************************************************************************
ETAPA 5 - IMPORTAR NOVO CONJUNTO DE TREINO BALANCEADO NO STATA
*******************************************************************************/
clear
* Adicionado varnames(1) e case(preserve)
import delimited "train_data_balanced.csv", varnames(1) case(preserve) clear encoding("UTF-8")

* Verificar se as vari√°veis existem ap√≥s a importa√ß√£o
describe Porte CNAE DivisaoCNAE NaturezaJuridica 

* Restaurar labels originais corretamente
* Certifique-se que os labels ainda s√£o aplic√°veis. SMOTE pode alterar a natureza dos dados.
* Considere recriar labels se necess√°rio, ou pular esta etapa se causar problemas.
capture do "`labels_backup'.do"

if _rc != 0 {
    di as error "‚ö†Ô∏è Falha ao restaurar labels. Verificar compatibilidade ap√≥s SMOTE."
}
else {
    di as text "‚úÖ Labels restaurados com sucesso ap√≥s SMOTE."
}

* Verificar balanceamento do conjunto de treino
tabulate FoiPenalizadoSTJ train

/*******************************************************************************
ETAPA 5.1 ‚Äì IMPORTAR CONJUNTO DE TESTE E JUNTAR √Ä BASE DE TREINO BALANCEADO
*******************************************************************************/
* Passo 1 ‚Äì Importar o conjunto de teste separadamente e salvar como tempor√°rio
clear
* Adicionado case(preserve)
import delimited "test_data.csv", varnames(1) case(preserve) encoding("UTF-8")
tempfile testdata
save `testdata', replace // Adicionado replace para seguran√ßa

* Passo 2 ‚Äì Agora importar o treino balanceado
clear
* Adicionado varnames(1) e case(preserve)
import delimited "train_data_balanced.csv", varnames(1) case(preserve) clear encoding("UTF-8")

* Passo 3 ‚Äì Restaurar os labels originais (novamente, verificar necessidade/compatibilidade)
capture do "`labels_backup'.do"
if _rc != 0 {
    di as error "Falha ao restaurar labels. Verificar compatibilidade ap√≥s SMOTE."
}

* Passo 4 ‚Äì Juntar com o conjunto de teste
* Verificar se as vari√°veis categ√≥ricas existem antes de juntar
describe Porte CNAE DivisaoCNAE NaturezaJuridica
append using `testdata'

* Passo 5 ‚Äì Verificar a distribui√ß√£o final por treino/teste
tabulate FoiPenalizadoSTJ train

* Verificar se as vari√°veis existem ap√≥s o append
describe Porte CNAE DivisaoCNAE NaturezaJuridica

/*******************************************************************************
ETAPA 5.1.1 ‚Äì AGRUPAMENTO DE CNAEs RAROS (CATEGORIAS COM POUCA FREQU√äNCIA)
*******************************************************************************/

* Define o m√≠nimo de ocorr√™ncias para manter CNAE como categoria isolada
local freq_minima = 10

* Cria um grupo especial para CNAEs com baixa frequ√™ncia
preserve

* Guardar vers√£o original, caso queira rastrear depois
gen CNAE_original = CNAE 

* Gerar mapa de frequ√™ncia dos CNAEs
contract CNAE
gen CNAE_agrupado = CNAE
replace CNAE_agrupado = -1 if _freq < `freq_minima'
tempfile freqmap
save `freqmap', replace

restore

* Aplicar o agrupamento via merge (sem 'nogen' para capturar _merge)
merge m:1 CNAE using `freqmap', keep(master match)

* Substituir CNAE por CNAE_agrupado apenas onde houver correspond√™ncia
replace CNAE = CNAE_agrupado if _merge == 3
drop _merge CNAE_agrupado _freq

* Verifica distribui√ß√£o ap√≥s o agrupamento
tabulate CNAE
di as text "‚úÖ Agrupamento de CNAEs raros conclu√≠do com base na frequ√™ncia m√≠nima de `freq_minima'."


/*******************************************************************************
ETAPA 5.2 ‚Äì CONVERTER VARI√ÅVEIS CATEG√ìRICAS PARA INTEIROS E GERAR DUMMIES (ap√≥s SMOTENC)
*******************************************************************************/
* Arredondar valores para garantir categorias inteiras
* Isso pode ser necess√°rio se o Python/SMOTE as transformou em float, mas idealmente n√£o deveria.
* Adicione verifica√ß√µes para evitar erros se a vari√°vel n√£o existir (embora agora deva existir)

capture confirm variable Porte
if _rc == 0 {
    replace Porte = round(Porte)
} 
else {
    di as error "Vari√°vel Porte ainda n√£o encontrada antes do round!"
}

capture confirm variable CNAE
if _rc == 0 {
    replace CNAE = round(CNAE)
} 
else {
    di as error "Vari√°vel CNAE n√£o encontrada antes do round!"
}

capture confirm variable NaturezaJuridica
if _rc == 0 {
    replace NaturezaJuridica = round(NaturezaJuridica)
} 
else {
    di as error "Vari√°vel NaturezaJuridica n√£o encontrada antes do round!"
}


capture confirm variable DivisaoCNAE
if _rc == 0 {
    replace DivisaoCNAE = round(DivisaoCNAE)
} 
else {
    di as error "Vari√°vel DivisaoCNAE n√£o encontrada antes do round!"
}

* Gerar vari√°veis dummies
* Adicione verifica√ß√µes aqui tamb√©m
capture confirm variable Porte
if _rc == 0 {
    tabulate Porte, generate(Porte_)
    drop Porte // Dropar original apenas se as dummies foram criadas
} 
else {
     di as error "N√£o foi poss√≠vel gerar dummies para Porte."
}

capture confirm variable CNAE
if _rc == 0 {
    tabulate CNAE, generate(CNAE_)
    drop CNAE
} 
else {
     di as error "N√£o foi poss√≠vel gerar dummies para CNAE."
}

capture confirm variable DivisaoCNAE
if _rc == 0 {
    tabulate DivisaoCNAE, generate(DivisaoCNAE_)
    drop DivisaoCNAE
} 
else {
     di as error "N√£o foi poss√≠vel gerar dummies para Divis√£o do CNAE."
}

capture confirm variable NaturezaJuridica
if _rc == 0 {
    tabulate NaturezaJuridica, generate(NaturezaJuridica_)
    drop NaturezaJuridica
} 
else {
     di as error "N√£o foi poss√≠vel gerar dummies para NaturezaJuridica."
}


/*******************************************************************************
ETAPA 6 - O CONJUNTO DE TESTE PERMANECE SEPARADO 
*******************************************************************************/
* O conjunto de teste ainda est√° salvo em "test_data.csv"
* Ele ser√° importado separadamente no final da an√°lise.

/******************************************************************************
Fornecer descri√ß√£o b√°sica da estrutura do conjunto de dados
*******************************************************************************/
describe

/*******************************************************************************
ETAPA 6 - AN√ÅLISE LOGIT

A vari√°vel dependente √© 'FoiPenalizadoSTJ', do tipo bin√°ria.
Ela indica se o fornecedor foi penalizado pelo STJ (1) ou n√£o (0).

As vari√°veis independentes ser√£o divididas em vari√°veis cont√°beis e vari√°veis de controle.

*******************************************************************************/

* 6.1 Listar todas as vari√°veis dispon√≠veis
ds

* Capturar todas as vari√°veis que come√ßam com "Porte_"
unab Porte_vars : Porte_*

* Capturar todas as vari√°veis que come√ßam com "CNAE_"
unab CNAE_vars : CNAE_*

* Capturar todas as vari√°veis que come√ßam com "NaturezaJuridica_"
unab Natureza_vars : NaturezaJuridica_*

* Definir vari√°veis cont√°beis (padronizadas e sint√©ticas)
local var_contabeis `Porte_vars' Liquidez_Media_Z Estrutura_Media_Z Margem_Media_Z ///
    z_LiqCorAjust z_EndGeral z_ImobRecNC z_CompEndivid z_GiroAtivo z_ROI z_ROE

* Definir vari√°veis de controle (padronizadas)
local var_controle `CNAE_vars' `Natureza_vars' z_vlrcontrato ///
    z_QtdeCNAEsSecundarios z_IdadedeAnos z_QtePenalOutrosOrgaos

* Executar a regress√£o log√≠stica no conjunto de treino
logit FoiPenalizadoSTJ `var_contabeis' `var_controle' if train == 1

* Armazenar os resultados do modelo completo
estimates store IRDCcompleto

/*******************************************************************************
Justificativa das Vari√°veis de Controle:

- **CNAE (Classifica√ß√£o Nacional de Atividades Econ√¥micas)**: Diferentes setores econ√¥micos possuem n√≠veis distintos de regula√ß√£o e riscos operacionais. Incluir o CNAE permite controlar os efeitos espec√≠ficos de cada setor na probabilidade de penaliza√ß√£o.

- **Natureza Jur√≠dica**: Empresas com diferentes naturezas jur√≠dicas t√™m estruturas legais e de governan√ßa distintas, o que pode influenciar a conformidade regulat√≥ria e o risco de penalidades.

- **log_vlrcontrato (Log do Valor do Contrato)**: Contratos de maior valor podem estar sujeitos a maior escrut√≠nio e complexidade, aumentando o risco de penalidades. O logaritmo √© usado para linearizar a rela√ß√£o.

- **QtdeCNAEsSecundarios (Quantidade de CNAEs Secund√°rios)**: Indica o n√≠vel de diversifica√ß√£o das atividades da empresa. Empresas mais diversificadas podem ter estruturas mais complexas, afetando a gest√£o e a conformidade regulat√≥ria.

- **IdadedeAnos (Idade da Empresa em Anos)**: Empresas mais antigas podem ter processos mais estabelecidos e experi√™ncia acumulada, afetando positivamente a conformidade com normas e regulamentos.

- **QtePenalOutrosOrgaos (Quantidade de Penalidades Aplicadas por Outros √ìrg√£os)**: Um hist√≥rico de penalidades pode indicar padr√µes de n√£o conformidade, aumentando a probabilidade de novas penaliza√ß√µes.

Essas vari√°veis de controle s√£o importantes para isolar o efeito das vari√°veis cont√°beis principais, garantindo que os resultados do modelo reflitam o impacto dos indicadores cont√°beis na probabilidade de penaliza√ß√£o, independentemente de outros fatores externos.

*******************************************************************************/

/*******************************************************************************
6.2 Regress√£o log√≠stica com sele√ß√£o stepwise a 10% de signific√¢ncia no conjunto de treinamento
*******************************************************************************/
* 6.1 Listar todas as vari√°veis dispon√≠veis
ds

* Capturar todas as vari√°veis que come√ßam com "Porte_"
unab Porte_vars : Porte_*

* Capturar todas as vari√°veis que come√ßam com "CNAE_"
unab CNAE_vars : CNAE_*

* Capturar todas as vari√°veis que come√ßam com "NaturezaJuridica_"
unab Natureza_vars : NaturezaJuridica_*

* Definir vari√°veis cont√°beis (padronizadas e sint√©ticas)
local var_contabeis `Porte_vars' Liquidez_Media_Z Estrutura_Media_Z Margem_Media_Z ///
    z_LiqCorAjust z_EndGeral z_ImobRecNC z_CompEndivid z_GiroAtivo z_ROI z_ROE

* Definir vari√°veis de controle (padronizadas)
local var_controle `CNAE_vars' `Natureza_vars' z_vlrcontrato ///
    z_QtdeCNAEsSecundarios z_IdadedeAnos z_QtePenalOutrosOrgaos

*Regress√£o log√≠stica com sele√ß√£o stepwise a 10% 
sw, pr(.10): logit FoiPenalizadoSTJ `var_contabeis' `var_controle' if train == 1

* Armazenar os resultados do modelo stepwise a 10%
estimates store IRDC10

* Teste de bondade de ajuste de Hosmer-Lemeshow para o modelo stepwise a 10%
estat gof if train == 1, group(10) table

/*******************************************************************************
6.2.2 Tabela de classifica√ß√£o para o modelo stepwise a 10% na base de treinamento
*******************************************************************************/
estat class if train == 1

* üìå Gerar predi√ß√µes na base de treinamento
capture drop prob_pred_treino
predict prob_pred_treino if train == 1, pr

* üìå Classifica√ß√£o prevista
capture drop predicted_class_treino
gen predicted_class_treino = (prob_pred_treino >= 0.5) if train == 1

* üìå Kappa na base de treinamento
*ssc install kappaetc, replace
kappaetc FoiPenalizadoSTJ predicted_class_treino if train == 1

* üìå Acur√°cia na base de treinamento
capture drop correct_classification_treino
gen correct_classification_treino = (FoiPenalizadoSTJ == predicted_class_treino) if train == 1
sum correct_classification_treino if train == 1
scalar prop_modelo_treino = r(mean)

* üìå No Information Rate (NIR)
*O NIR representa a acur√°cia de um modelo nulo (baseline), que classifica sempre a categoria mais frequente.
tabulate FoiPenalizadoSTJ if train == 1, matcell(freq_treino)
scalar total_treino = freq_treino[1,1] + freq_treino[2,1]
scalar max_treino = max(freq_treino[1,1], freq_treino[2,1])
scalar prop_nir_treino = max_treino / total_treino

* üìå Compara√ß√£o
di "Acur√°cia na base de treinamento: " prop_modelo_treino
di "NIR (treinamento): " prop_nir_treino

if (prop_modelo_treino > prop_nir_treino) {
    di "‚úÖ Modelo stepwise 10% supera o NIR na base de treino."
}
else {
    di "‚ö†Ô∏è Modelo stepwise 10% N√ÉO supera o NIR na base de treino."
}

* üìå Teste de McNemar na base de treinamento
* Criar a matriz de confus√£o da base de teste
tabulate FoiPenalizadoSTJ predicted_class_treino if train == 1, matcell(mc_treino)

* Extrair os valores da matriz
scalar tn_treino = mc_treino[1,1] // Verdadeiro Negativo
scalar fn_treino = mc_treino[2,1] // Falso Negativo
scalar fp_treino = mc_treino[1,2] // Falso Positivo
scalar tp_treino = mc_treino[2,2] // Verdadeiro Positivo

* Mostrar os valores extra√≠dos (opcional)
di "TN: " tn_treino
di "FN: " fn_treino
di "FP: " fp_treino
di "TP: " tp_treino

* Rodar o teste de McNemar com os valores num√©ricos
mcci `=tn_treino' `=fn_treino' `=fp_treino' `=tp_treino'

/*******************************************************************************
6.2.3 Curva ROC para o modelo stepwise a 10% na base de TREINO
*******************************************************************************/
lroc if train == 1
graph export "lroc_IRDC10_treino.png", replace

/*******************************************************************************
6.2.4 Tabela de classifica√ß√£o para o modelo stepwise a 10% na base de TESTE
*******************************************************************************/
estat class if train == 0

* üìå Gerar predi√ß√µes na base de teste
capture drop prob_pred_teste
predict prob_pred_teste if train == 0, pr

* üìå Classifica√ß√£o prevista
capture drop predicted_class_teste
gen predicted_class_teste = (prob_pred_teste >= 0.5) if train == 0

* üìå Kappa na base de teste
kappaetc FoiPenalizadoSTJ predicted_class_teste if train == 0

* üìå Acur√°cia na base de teste
capture drop correct_classification_teste
gen correct_classification_teste = (FoiPenalizadoSTJ == predicted_class_teste) if train == 0
sum correct_classification_teste if train == 0
scalar prop_modelo_teste = r(mean)

* üìå No Information Rate (NIR)
tabulate FoiPenalizadoSTJ if train == 0, matcell(freq_teste)
scalar total_teste = freq_teste[1,1] + freq_teste[2,1]
scalar max_teste = max(freq_teste[1,1], freq_teste[2,1])
scalar prop_nir_teste = max_teste / total_teste


* üìå Compara√ß√£o
di "Acur√°cia na base de teste: " prop_modelo_teste
di "NIR (teste): " prop_nir_teste

if (prop_modelo_teste > prop_nir_teste) {
    di "‚úÖ Modelo stepwise 10% supera o NIR na base de teste."
}
else {
    di "‚ö†Ô∏è Modelo stepwise 10% N√ÉO supera o NIR na base de teste."
}

* üìå Teste de McNemar na base de teste
* Criar a matriz de confus√£o da base de teste
tabulate FoiPenalizadoSTJ predicted_class_teste if train == 0, matcell(mc_teste)

* Extrair os valores da matriz
scalar tn_teste = mc_teste[1,1] // Verdadeiro Negativo
scalar fn_teste = mc_teste[2,1] // Falso Negativo
scalar fp_teste = mc_teste[1,2] // Falso Positivo
scalar tp_teste = mc_teste[2,2] // Verdadeiro Positivo

* Mostrar os valores extra√≠dos (opcional)
di "TN: " tn_teste
di "FN: " fn_teste
di "FP: " fp_teste
di "TP: " tp_teste

* Rodar o teste de McNemar com os valores num√©ricos
mcci `=tn_teste' `=fn_teste' `=fp_teste' `=tp_teste'

/*******************************************************************************
6.2.5 Curva ROC para o modelo stepwise a 10% na base de TESTE
*******************************************************************************/
lroc if train == 0
graph export "lroc_IRDC10_teste.png", replace

/*******************************************************************************
6.2.6 ‚Äì Ponto de Corte Ideal (Sensibilidade ‚âà Especificidade)
*******************************************************************************/

* Reexecutar rapidamente o modelo (sem sobrescrever)
quietly logit FoiPenalizadoSTJ `var_contabeis' `var_controle' if train == 1

* Restaurar modelo salvo
estimates restore IRDC10

* üìå BASE DE TREINAMENTO
* ------------------------------------------------------------
* Garantir que as vari√°veis tempor√°rias n√£o existam
capture drop prob_pred_treino
capture drop cutoff
capture drop sens
capture drop spec
capture drop difference
capture drop abs_diff
capture drop ordem

* Gerar predi√ß√µes
predict prob_pred_treino if train == 1, pr

* Gerar sensitividade e especificidade para diferentes cutoffs
lsens if train == 1, genprob(cutoff) gensens(sens) genspec(spec) nograph

* Calcular diferen√ßa entre sensibilidade e especificidade
gen difference = sens - spec
gen abs_diff = abs(difference)

* Obter ponto ideal (menor diferen√ßa)
gen ordem = _n
gsort abs_diff

* Salvar valores do melhor ponto em scalars usando summarize
summarize cutoff if abs_diff == abs_diff[1]
scalar cutoff_ideal_treino = r(mean)

summarize sens if abs_diff == abs_diff[1]
scalar sens_ideal_treino = r(mean)
scalar cutoff_step10 = cutoff_ideal_treino


summarize spec if abs_diff == abs_diff[1]
scalar spec_ideal_treino = r(mean)

* Mostrar o ponto ideal encontrado
list cutoff sens spec abs_diff in 1, noobs clean

* Plotar gr√°fico com destaque no ponto de cruzamento
lsens if train == 1, ///
    yline(`=sens_ideal_treino') xline(`=cutoff_ideal_treino') ///
    scheme(s1color) ///
    ylab(0 0.2 `=sens_ideal_treino' 0.8 1) ///
    xlab(0 0.2 `=cutoff_ideal_treino' 0.8 1)

graph export "cutoff_ideal_IRDC10_treino.png", replace

/*******************************************************************************
6.2.7 ‚Äì Tabela de Classifica√ß√£o com Cutoff Ideal (Treinamento e Teste)
*******************************************************************************/

* üìå BASE DE TREINAMENTO
* ------------------------------------------------------------

di "Tabela de classifica√ß√£o utilizando o cutoff ideal da base de TREINAMENTO: " cutoff_ideal_treino

* Gerar classifica√ß√£o com o cutoff ideal
capture drop predicted_class_treino
gen predicted_class_treino = (prob_pred_treino >= cutoff_ideal_treino) if train == 1

* Matriz de classifica√ß√£o detalhada
estat class if train == 1

* Kappa
kappaetc FoiPenalizadoSTJ predicted_class_treino if train == 1

* Acur√°cia
capture drop correct_classification_treino
gen correct_classification_treino = (FoiPenalizadoSTJ == predicted_class_treino) if train == 1
sum correct_classification_treino if train == 1
scalar prop_modelo_treino = r(mean)

* No Information Rate
tabulate FoiPenalizadoSTJ if train == 1, matcell(freq_treino)
scalar total_treino = freq_treino[1,1] + freq_treino[2,1]
scalar max_treino = max(freq_treino[1,1], freq_treino[2,1])
scalar prop_nir_treino = max_treino / total_treino

di "Acur√°cia (treino): " prop_modelo_treino
di "NIR (treino): " prop_nir_treino

if (prop_modelo_treino > prop_nir_treino) {
    di "‚úÖ Modelo stepwise 10% supera o NIR na base de treino (cutoff ideal)."
}
else {
    di "‚ö†Ô∏è Modelo stepwise 10% N√ÉO supera o NIR na base de treino (cutoff ideal)."
}

* Teste de McNemar
tabulate FoiPenalizadoSTJ predicted_class_treino if train == 1, matcell(mc_treino)
scalar tn_treino = mc_treino[1,1]
scalar fn_treino = mc_treino[2,1]
scalar fp_treino = mc_treino[1,2]
scalar tp_treino = mc_treino[2,2]
mcci `=tn_treino' `=fn_treino' `=fp_treino' `=tp_treino'


* üìå BASE DE TESTE
* ------------------------------------------------------------

di "Tabela de classifica√ß√£o utilizando o cutoff ideal da base de TREINAMENTO (aplicado na base de TESTE): " cutoff_ideal_treino

* Gerar classifica√ß√£o com o mesmo cutoff da base de teste
capture drop predicted_class_teste
gen predicted_class_teste = (prob_pred_teste >= cutoff_ideal_treino) if train == 0

* Matriz de classifica√ß√£o detalhada
estat class if train == 0

* Kappa
kappaetc FoiPenalizadoSTJ predicted_class_teste if train == 0

* Acur√°cia
capture drop correct_classification_teste
gen correct_classification_teste = (FoiPenalizadoSTJ == predicted_class_teste) if train == 0
sum correct_classification_teste if train == 0
scalar prop_modelo_teste = r(mean)

* No Information Rate
tabulate FoiPenalizadoSTJ if train == 0, matcell(freq_teste)
scalar total_teste = freq_teste[1,1] + freq_teste[2,1]
scalar max_teste = max(freq_teste[1,1], freq_teste[2,1])
scalar prop_nir_teste = max_teste / total_teste

di "Acur√°cia (teste): " prop_modelo_teste
di "NIR (teste): " prop_nir_teste

if (prop_modelo_teste > prop_nir_teste) {
    di "‚úÖ Modelo stepwise 10% supera o NIR na base de teste (cutoff ideal do treino)."
}
else {
    di "‚ö†Ô∏è Modelo stepwise 10% N√ÉO supera o NIR na base de teste (cutoff ideal do treino)."
}

* Teste de McNemar
tabulate FoiPenalizadoSTJ predicted_class_teste if train == 0, matcell(mc_teste)
scalar tn_teste = mc_teste[1,1]
scalar fn_teste = mc_teste[2,1]
scalar fp_teste = mc_teste[1,2]
scalar tp_teste = mc_teste[2,2]
mcci `=tn_teste' `=fn_teste' `=fp_teste' `=tp_teste'

/*******************************************************************************
6.3 Regress√£o log√≠stica com sele√ß√£o via LASSO (penaliza√ß√£o L1) no conjunto de treinamento

 O LASSO (Least Absolute Shrinkage and Selection Operator) realiza sele√ß√£o autom√°tica
de vari√°veis e reduz o risco de overfitting (sobreajuste), especialmente √∫til em 
modelos com muitas vari√°veis e potencial multicolinearidade.

*******************************************************************************/

* 6.1 Listar todas as vari√°veis dispon√≠veis
ds

* Capturar todas as vari√°veis que come√ßam com "Porte_"
unab Porte_vars : Porte_*

* Capturar todas as vari√°veis que come√ßam com "CNAE_"
unab CNAE_vars : CNAE_*

* Capturar todas as vari√°veis que come√ßam com "NaturezaJuridica_"
unab Natureza_vars : NaturezaJuridica_*

* Definir vari√°veis cont√°beis (padronizadas e sint√©ticas)
local var_contabeis `Porte_vars' Liquidez_Media_Z Estrutura_Media_Z Margem_Media_Z ///
    z_LiqCorAjust z_EndGeral z_ImobRecNC z_CompEndivid z_GiroAtivo z_ROI z_ROE

* Definir vari√°veis de controle (padronizadas)
local var_controle `CNAE_vars' `Natureza_vars' z_vlrcontrato ///
    z_QtdeCNAEsSecundarios z_IdadedeAnos z_QtePenalOutrosOrgaos

* Consolidar todas as vari√°veis em uma macro
local todas_vars `var_contabeis' `var_controle'

*Ajustar modelo LASSO na base de treinamento
lasso logit FoiPenalizadoSTJ `todas_vars' if train == 1, selection(cv)

* Salvar modelo
estimates store IRDC_LASSO


/*******************************************************************************
6.3.1 ‚Äì Exportar Coeficientes Selecionados do Modelo LASSO (via log + convers√£o via Python)
*******************************************************************************/

* Garantir que qualquer log anterior esteja fechado
capture log close lassolog

* Abrir log no diret√≥rio atual (o mesmo de execu√ß√£o)
log using "coef_lasso.txt", name(lassolog) text replace

* Exibir os coeficientes selecionados
lassocoef, display(coef, postselection)

* Fechar o log
log close lassolog

display "‚úÖ coef_lasso.txt exportado com sucesso."


/*******************************************************************************
6.3.2 Tabela de Classifica√ß√£o, Acur√°cia, NIR e Teste de McNemar para o 
Modelo LASSO na base de treino
*******************************************************************************/

* üìå Gerar predi√ß√µes de probabilidade na base de treinamento
capture drop prob_pred_lasso
predict prob_pred_lasso if train == 1, xb

* üìå Classifica√ß√£o prevista com cutoff 0.5
capture drop pred_lasso
gen pred_lasso = (prob_pred_lasso >= 0.5) if train == 1

* üìå Kappa
kappaetc FoiPenalizadoSTJ pred_lasso if train == 1

* üìå Acur√°cia na base de treinamento
capture drop correct_lasso
gen correct_lasso = (FoiPenalizadoSTJ == pred_lasso) if train == 1
sum correct_lasso if train == 1
scalar acuracia = r(mean)

* üìå No Information Rate (NIR)
* O NIR representa a acur√°cia de um modelo nulo (baseline), que classifica sempre a categoria mais frequente
tabulate FoiPenalizadoSTJ if train == 1, matcell(freq_lasso)
scalar total_lasso = freq_lasso[1,1] + freq_lasso[2,1]
scalar max_lasso = max(freq_lasso[1,1], freq_lasso[2,1])
scalar prop_nir_lasso = max_lasso / total_lasso

* üìå Compara√ß√£o
di "Acur√°cia LASSO na base de treinamento: " acuracia
di "NIR (treinamento): " prop_nir_lasso

if (acuracia > prop_nir_lasso) {
    di "‚úÖ Modelo LASSO supera o NIR na base de treino."
}
else {
    di "‚ö†Ô∏è Modelo LASSO N√ÉO supera o NIR na base de treino."
}

* üìå Teste de McNemar na base de treinamento
tabulate FoiPenalizadoSTJ pred_lasso if train == 1, matcell(mc_lasso)

scalar tn_lasso = mc_lasso[1,1] // Verdadeiro Negativo
scalar fn_lasso = mc_lasso[2,1] // Falso Negativo
scalar fp_lasso = mc_lasso[1,2] // Falso Positivo
scalar tp_lasso = mc_lasso[2,2] // Verdadeiro Positivo

* Mostrar os valores extra√≠dos (opcional)
di "TN: " tn_lasso
di "FN: " fn_lasso
di "FP: " fp_lasso
di "TP: " tp_lasso

* Rodar o teste de McNemar com os valores num√©ricos
mcci `=tn_lasso' `=fn_lasso' `=fp_lasso' `=tp_lasso'

/*******************************************************************************
6.3.3 Curva ROC para o modelo LASSO na base de TREINO
*******************************************************************************/
capture drop prob_pred_lasso_treino
predict prob_pred_lasso_treino if train == 1, xb
roctab FoiPenalizadoSTJ prob_pred_lasso_treino if train == 1, graph
graph export "ROC_LASSO_treino.png", replace

/*******************************************************************************
6.3.4 Avalia√ß√£o do modelo LASSO na base de TESTE
*******************************************************************************/

* üìå Gerar predi√ß√µes de probabilidade na base de teste
capture drop prob_pred_lasso_teste
predict prob_pred_lasso_teste if train == 0, xb

* üìå Classifica√ß√£o prevista com cutoff 0.5
capture drop pred_lasso_teste
gen pred_lasso_teste = (prob_pred_lasso_teste >= 0.5) if train == 0

* üìå Kappa na base de teste
kappaetc FoiPenalizadoSTJ pred_lasso_teste if train == 0

* üìå Acur√°cia na base de teste
capture drop correct_lasso_teste
gen correct_lasso_teste = (FoiPenalizadoSTJ == pred_lasso_teste) if train == 0
sum correct_lasso_teste if train == 0
scalar acuracia_teste = r(mean)

* üìå No Information Rate (NIR) - TESTE
tabulate FoiPenalizadoSTJ if train == 0, matcell(freq_teste)
scalar total_teste = freq_teste[1,1] + freq_teste[2,1]
scalar max_teste = max(freq_teste[1,1], freq_teste[2,1])
scalar nir_teste = max_teste / total_teste

di "Acur√°cia LASSO (teste): " acuracia_teste
di "NIR (teste): " nir_teste

if (acuracia_teste > nir_teste) {
    di "‚úÖ Modelo LASSO supera o NIR na base de teste."
}
else {
    di "‚ö†Ô∏è Modelo LASSO N√ÉO supera o NIR na base de teste."
}

* üìå Teste de McNemar - TESTE
tabulate FoiPenalizadoSTJ pred_lasso_teste if train == 0, matcell(mc_lasso_teste)

scalar tn_teste = mc_lasso_teste[1,1]
scalar fn_teste = mc_lasso_teste[2,1]
scalar fp_teste = mc_lasso_teste[1,2]
scalar tp_teste = mc_lasso_teste[2,2]

di "TN: " tn_teste
di "FN: " fn_teste
di "FP: " fp_teste
di "TP: " tp_teste

mcci `=tn_teste' `=fn_teste' `=fp_teste' `=tp_teste'

/*******************************************************************************
6.3.5 Curva ROC para o modelo LASSO na base de TESTE
*******************************************************************************/
roctab FoiPenalizadoSTJ prob_pred_lasso_teste if train == 0, graph
graph export "ROC_LASSO_teste.png", replace

/*******************************************************************************
6.3.6 ‚Äì Classifica√ß√£o com Cutoff M√©dio (modelo LASSO)
*******************************************************************************/

* üìå Definir o cutoff m√©dio com base nos modelos completos, stepwise 5% e stepwise 10%
scalar cutoff_medio = cutoff_step10
di "üìå Cutoff m√©dio dos modelos: " cutoff_medio

* ========================================================
* BASE DE TREINAMENTO
* ========================================================

* üìå Gerar classifica√ß√£o com cutoff m√©dio
capture drop predicted_class_lasso_treino
gen predicted_class_lasso_treino = (prob_pred_lasso_treino >= cutoff_medio) if train == 1

* üìå Matriz de classifica√ß√£o com tabula√ß√£o
tabulate FoiPenalizadoSTJ predicted_class_lasso_treino if train == 1, matcell(mc_lasso_treino)

* üìå Extrair valores
scalar tn_lasso_medio = mc_lasso_treino[1,1]
scalar fn_lasso_medio = mc_lasso_treino[2,1]
scalar fp_lasso_medio = mc_lasso_treino[1,2]
scalar tp_lasso_medio = mc_lasso_treino[2,2]

* üìå Kappa
kappaetc FoiPenalizadoSTJ predicted_class_lasso_treino if train == 1

* üìå Acur√°cia
capture drop correct_lasso_medio
gen correct_lasso_medio = (FoiPenalizadoSTJ == predicted_class_lasso_treino) if train == 1
sum correct_lasso_medio if train == 1
scalar acuracia_lasso_medio = r(mean)

* üìå No Information Rate (NIR)
tabulate FoiPenalizadoSTJ if train == 1, matcell(freq_lasso_medio)
scalar total_lasso_medio = freq_lasso_medio[1,1] + freq_lasso_medio[2,1]
scalar max_lasso_medio = max(freq_lasso_medio[1,1], freq_lasso_medio[2,1])
scalar nir_lasso_medio = max_lasso_medio / total_lasso_medio

di "Acur√°cia (treino, cutoff m√©dio): " acuracia_lasso_medio
di "NIR (treino, cutoff m√©dio): " nir_lasso_medio

if (acuracia_lasso_medio > nir_lasso_medio) {
    di "‚úÖ Modelo LASSO (cutoff m√©dio) supera o NIR na base de treino."
}
else {
    di "‚ö†Ô∏è Modelo LASSO (cutoff m√©dio) N√ÉO supera o NIR na base de treino."
}

* üìå Teste de McNemar
mcci `=tn_lasso_medio' `=fn_lasso_medio' `=fp_lasso_medio' `=tp_lasso_medio'

* ========================================================
* BASE DE TESTE
* ========================================================

* üìå Gerar classifica√ß√£o com cutoff m√©dio
capture drop predicted_class_lasso_teste
gen predicted_class_lasso_teste = (prob_pred_lasso_teste >= cutoff_medio) if train == 0

* üìå Matriz de classifica√ß√£o com tabula√ß√£o
tabulate FoiPenalizadoSTJ predicted_class_lasso_teste if train == 0, matcell(mc_lasso_teste)

* üìå Extrair valores
scalar tn_lasso_medio_teste = mc_lasso_teste[1,1]
scalar fn_lasso_medio_teste = mc_lasso_teste[2,1]
scalar fp_lasso_medio_teste = mc_lasso_teste[1,2]
scalar tp_lasso_medio_teste = mc_lasso_teste[2,2]

* üìå Kappa
kappaetc FoiPenalizadoSTJ predicted_class_lasso_teste if train == 0

* üìå Acur√°cia
capture drop correct_lasso_medio_teste
gen correct_lasso_medio_teste = (FoiPenalizadoSTJ == predicted_class_lasso_teste) if train == 0
sum correct_lasso_medio_teste if train == 0
scalar acuracia_lasso_medio_teste = r(mean)

* üìå No Information Rate (NIR)
tabulate FoiPenalizadoSTJ if train == 0, matcell(freq_lasso_medio_teste)
scalar total_lasso_medio_teste = freq_lasso_medio_teste[1,1] + freq_lasso_medio_teste[2,1]
scalar max_lasso_medio_teste = max(freq_lasso_medio_teste[1,1], freq_lasso_medio_teste[2,1])
scalar nir_lasso_medio_teste = max_lasso_medio_teste / total_lasso_medio_teste

di "Acur√°cia (teste, cutoff m√©dio): " acuracia_lasso_medio_teste
di "NIR (teste, cutoff m√©dio): " nir_lasso_medio_teste

if (acuracia_lasso_medio_teste > nir_lasso_medio_teste) {
    di "‚úÖ Modelo LASSO (cutoff m√©dio) supera o NIR na base de teste."
}
else {
    di "‚ö†Ô∏è Modelo LASSO (cutoff m√©dio) N√ÉO supera o NIR na base de teste."
}

* üìå Teste de McNemar
mcci `=tn_lasso_medio_teste' `=fn_lasso_medio_teste' `=fp_lasso_medio_teste' `=tp_lasso_medio_teste'


*******************************************************************************/


/*******************************************************************************
FIM DO SCRIPT
*******************************************************************************/

log off